{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Artificial Intelligence and Society 2024/2025**\n",
    "**Miriam Seoane Santos** (FCUP/DCC & LIAAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **T07: Missing Data Generation and Imputation**\n",
    "\n",
    "In this tutorial, we will explore the basic concepts related to **missing data**. \n",
    "\n",
    "We will simulate the missing data problem in the **iris dataset** and mitigate it using data imputation (i.e., replacing the missing values with plausible estimates). To that end, we will apply three different imputation techniques and assess their impact on classification performance. \n",
    "\n",
    "In terms of software, we will essentially rely on the [scikit-learn](https://scikit-learn.org/stable/modules/impute.html) standard stack, and the Missing Completely At Random (MCAR) mechanism, which we will also implement. You may further explore other missing data mechanisms implemented in [mdatagen](https://arthurmangussi.github.io/pymdatagen/).\n",
    " \n",
    "1. Basic Setup and Util Functions\n",
    "2. Exploring Mean Imputation\n",
    "3. Exploring KNN Imputation\n",
    "4. Exploring MICE Imputation\n",
    "\n",
    "*Let's get started!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic Setup and Util Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We start by importing the necessary modules, loading the iris dataset, artificially inject it with missing values following a MCAR mechanisms, and create an auxiliary function that trains and evaluates a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predefine a missing rate to be used across the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try 0.1, 0.3, and 0.5.\n",
    "MISSING_RATE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the **iris dataset** into the variables `X` (containing the data features) and `y` (containing the target labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simulate MCAR by creating a random number generator and defining a mask to introduce missing values into the dataset `X` based on the predefined missing rate. The selected positions in `X` are replace with **NaN** values to simulate missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "missing_mask = rng.choice([0, 1], X.shape,\n",
    "                          p=[1. - MISSING_RATE, MISSING_RATE])\n",
    "missing_mask = np.argwhere(missing_mask == 1)\n",
    "X[missing_mask[:, 0], missing_mask[:, 1]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m----> 2\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(X)\n\u001b[1;32m      4\u001b[0m missing_rate \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlobal Missing Rate = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_rate\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if isinstance(X, np.ndarray):\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "missing_rate = X.isnull().sum().sum() / X.size\n",
    "print(f\"Global Missing Rate = {missing_rate * 100:.0f}%\")\n",
    "print(\"Missing values per column:\")\n",
    "print(X.isnull().sum())  # Missing values per column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the dataset `X` and labels `y` into training and test sets (`X_train`, `X_test`, `y_train`, `y_test`) while preserving the original class distribution using stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, it is defined a helper `run_logistic_regression` function train, that evaluates a logistic regression model by imputing missing values in the training set and testing data using a specified imputer, fitting the model on the training data, predicting the labels for the testing data, and returning the predictions along with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression(X_train_lr, X_test_lr, y_train_lr, y_test_lr, imputer):\n",
    "    X_train_lr = imputer.fit_transform(X_train_lr)\n",
    "    X_test_lr = imputer.fit_transform(X_test_lr)        # Maybe change to fit on training?\n",
    "\n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    clf.fit(X_train_lr, y_train_lr)\n",
    "    y_pred = clf.predict(X_test_lr)\n",
    "\n",
    "    report = classification_report(y_test_lr, y_pred)\n",
    "    return y_pred, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploring Mean Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a `SimpleImputer` to fill missing values with the mean, and then train a logistic regression model using the imputed data, and printing the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Mean Imputation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.73      0.92      0.81        12\n",
      "           2       0.90      0.69      0.78        13\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.88      0.87      0.87        38\n",
      "weighted avg       0.88      0.87      0.87        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "y_pred, clf_report = run_logistic_regression(X_train, X_test, y_train, y_test, simple_imputer)\n",
    "print(\"Results with Mean Imputation\")\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploring kNN Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than the mean, we can decide on a `KNNImputer` with `k=5` to fill missing values. Similarly, we train a logistic regression model using the imputed data, and print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with kNN Imputation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.92      1.00      0.96        12\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "y_pred, clf_report = run_logistic_regression(X_train, X_test, y_train, y_test, knn_imputer)\n",
    "print(\"Results with kNN Imputation\")\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploring MICE Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we explore MICE by creating an `IterativeImputer` with 100 iterations to fill missing values. The `IterativeImputer` implements the MICE behavior, automatically aggregating the results into a single imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with MICE Imputation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.98      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/.local/lib/python3.10/site-packages/sklearn/impute/_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mice_imputer = IterativeImputer(max_iter=100)\n",
    "y_pred, clf_report = run_logistic_regression(X_train, X_test, y_train, y_test, mice_imputer)\n",
    "print(\"Results with MICE Imputation\")\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bibliography**\n",
    "- To consolidate the concepts discussed herein, please refer to the following:\n",
    "    - Van Buuren, Stef. [Flexible imputation of missing data](https://stefvanbuuren.name/fimd/). CRC press, 2018.\n",
    "    - [Imputation of Missing Values](https://scikit-learn.org/stable/modules/impute.html), scikit-learn documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
